<!doctype html><html class="theme-next mist use-motion" lang="zh-Hans"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css"><meta name="keywords" content="k8s,cncf,storage,"><link rel="alternate" href="/atom.xml" title="月星墙的博客" type="application/atom+xml"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1"><meta name="description" content="简介 TODO rook v1.1.2 测试使用不是很流畅，会出现一些诡异的问题，待rook毕业 Rook 是Kubernetes的开源云本地存储协调器，为各种存储解决方案提供平台，框架和支持，以便与云原生环境本地集成。是云原生计算基金会(CNCF)的孵化级项目。Rook 目前支持 Ceph、NFS、Minio Object Store、Edegefs、Cassandra、CockroachDB"><meta name="keywords" content="k8s,cncf,storage"><meta property="og:type" content="article"><meta property="og:title" content="Rook | K8s存储协调器"><meta property="og:url" content="http://blog.aezo.cn/2019/09/23/devops/rook/index.html"><meta property="og:site_name" content="月星墙的博客"><meta property="og:description" content="简介 TODO rook v1.1.2 测试使用不是很流畅，会出现一些诡异的问题，待rook毕业 Rook 是Kubernetes的开源云本地存储协调器，为各种存储解决方案提供平台，框架和支持，以便与云原生环境本地集成。是云原生计算基金会(CNCF)的孵化级项目。Rook 目前支持 Ceph、NFS、Minio Object Store、Edegefs、Cassandra、CockroachDB"><meta property="og:locale" content="zh-Hans"><meta property="og:updated_time" content="2021-08-31T06:07:20.347Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Rook | K8s存储协调器"><meta name="twitter:description" content="简介 TODO rook v1.1.2 测试使用不是很流畅，会出现一些诡异的问题，待rook毕业 Rook 是Kubernetes的开源云本地存储协调器，为各种存储解决方案提供平台，框架和支持，以便与云原生环境本地集成。是云原生计算基金会(CNCF)的孵化级项目。Rook 目前支持 Ceph、NFS、Minio Object Store、Edegefs、Cassandra、CockroachDB"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Mist",sidebar:{position:"right",display:"post",offset:12,offset_float:0,b2t:!1,scrollpercent:!1},fancybox:!0,motion:!0,duoshuo:{userId:"0",author:"博主"},algolia:{applicationID:"BWD6R9FA4K",apiKey:"3330f3cbaa099dfc30395de5f5b20151",indexName:"blog",hits:{per_page:10},labels:{input_placeholder:"请输入关键字",hits_empty:"我们没有找到任何搜索结果: ${query}",hits_stats:"找到约${hits}条结果（用时${time}ms）"}}}</script><link rel="canonical" href="http://blog.aezo.cn/2019/09/23/devops/rook/"><title>Rook | K8s存储协调器 | 月星墙的博客</title><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?085f9cd91ef2ad985f791c677472f0d1";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"><div class="container sidebar-position-right page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">月星墙的博客</span><span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description">Better Code, Better Life</h1></div><div class="site-nav-toggle"> <button><span class="btn-bar"></span><span class="btn-bar"></span><span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br> 首页</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br> 分类</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i><br> 关于</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br> 归档</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br> 标签</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="menu-item-icon fa fa-fw fa-sitemap"></i><br> 站点地图</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br> 搜索</a></li></ul><div class="site-search"><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class="search-icon"><i class="fa fa-search"></i></span><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span><div class="local-search-input-wrapper"> <input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input"></div></div><div id="local-search-result"></div></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><link itemprop="mainEntityOfPage" href="http://blog.aezo.cn/2019/09/23/devops/rook/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="smalle"><meta itemprop="description" content=""><meta itemprop="image" content="https://avatars0.githubusercontent.com/u/15698218?v=3&u=ce740bf0b67ff0d74990ba6fc644d6e92f572dcb&s=400"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="月星墙的博客"></span><header class="post-header"><h2 class="post-title" itemprop="name headline">Rook | K8s存储协调器</h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-23T09:38:00+08:00">2019-09-23</time></span> <span class="post-category"><span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/devops/" itemprop="url" rel="index"><span itemprop="name">devops</span></a></span></span></div></header><div class="post-body" itemprop="articleBody"><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><ul><li>TODO rook v1.1.2 测试使用不是很流畅，会出现一些诡异的问题，待rook毕业</li><li><a href="https://rook.io" target="_blank" rel="noopener">Rook</a> 是Kubernetes的开源云本地存储协调器，为各种存储解决方案提供平台，框架和支持，以便与云原生环境本地集成。是云原生计算基金会(CNCF)的孵化级项目。Rook 目前支持 <code>Ceph</code>、<code>NFS</code>、<code>Minio Object Store</code>、<code>Edegefs</code>、<code>Cassandra</code>、<code>CockroachDB</code> 存储的搭建，使用 Rook 可以轻松实现在 Kubernetes 上部署并运行 Ceph 存储系统</li></ul><h2 id="Rook-Ceph"><a href="#Rook-Ceph" class="headerlink" title="Rook-Ceph"></a>Rook-Ceph</h2><ul><li><a href="https://ceph.com/" target="_blank" rel="noopener">Ceph</a> 是一个分布式存储系统，目前提供<code>对象存储(RADOSGW)</code>、<code>块存储RDB</code>以及<code>CephFS文件系统</code>这3种功能，并且提供Ceph REST API。具体见<a href="/_posts/devops/ceph.md">http://blog.aezo.cn/2019/11/14/devops/ceph/</a> <a href="https://www.cnblogs.com/yangxiaoyi/p/7795274.html" target="_blank" rel="noopener">^1</a></li><li>k8s存储选型：<code>Rook</code>/<code>Ceph</code> <a href="https://blog.fleeto.us/post/kubernetes-storage-performance-comparison/" title="Kubernetes 存储性能对比" target="_blank" rel="noopener">^2</a></li></ul><h3 id="安装-Rook-Ceph"><a href="#安装-Rook-Ceph" class="headerlink" title="安装 Rook-Ceph"></a>安装 Rook-Ceph</h3><ul><li>参考 <a href="https://rook.io/docs/rook/v1.1/ceph-quickstart.html" target="_blank" rel="noopener">https://rook.io/docs/rook/v1.1/ceph-quickstart.html</a> <a href="https://sealyun.com/post/rook" target="_blank" rel="noopener">^3</a></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 所有节点开启ip_forward，k8s的node节点一般都已经开启过</span></span><br><span class="line">cat &gt; /etc/sysctl.d/ceph.conf &lt;&lt; EOF</span><br><span class="line">net.ipv4.ip_forward = 1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables = 1</span><br><span class="line">net.bridge.bridge-nf-call-iptables = 1</span><br><span class="line">EOF</span><br><span class="line">sysctl --system</span><br><span class="line"></span><br><span class="line"><span class="comment">### 开始部署Operator</span></span><br><span class="line"><span class="built_in">cd</span> /home/smalle/k8s</span><br><span class="line">wget https://github.com/rook/rook/archive/v1.1.2.tar.gz</span><br><span class="line">tar -zxvf v1.1.2.tar.gz</span><br><span class="line"><span class="built_in">cd</span> rook-1.1.2/cluster/examples/kubernetes/ceph</span><br><span class="line"><span class="comment">## 安装并查看operator是否成功(会创建命名空间rook-ceph)</span></span><br><span class="line">kubectl apply -f common.yaml</span><br><span class="line"><span class="comment"># 修改镜像配置</span></span><br><span class="line"><span class="comment"># 如默认使用CSI驱动，需修改相关插件镜像，见下文说明。CSI驱动程序，它是K8s 1.13及更高版本以后的首选驱动程序，较早的Flex驱动默认是关闭的</span></span><br><span class="line">sed -i <span class="string">'s#quay.io#quay.mirrors.ustc.edu.cn#g'</span> operator.yaml <span class="comment"># 修改镜像后，启用此镜像</span></span><br><span class="line">vi operator.yaml</span><br><span class="line">kubectl apply -f operator.yaml</span><br><span class="line"><span class="comment"># 需要等几分钟，确保 rook-ceph-operator 处于 `Running` 状态，`rook-discover` 会在无污点(k8s-master有污点)的所有节点上运行。`rook-ceph-agent` 在Flex模式才会产生(默认是CSI模式)</span></span><br><span class="line">kubectl -n rook-ceph get pod -o wide</span><br><span class="line"></span><br><span class="line"><span class="comment">### 设置节点标签。(测试环境 node1 为k8s-master节点，所有默认无法被调度)</span></span><br><span class="line">kubectl label nodes &#123;node2,node3&#125; storage-node=<span class="built_in">enable</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 部署集群</span></span><br><span class="line"><span class="comment">## 修改集群配置 cluster.yaml，见下文说明。官方说明 https://rook.io/docs/rook/v1.1/ceph-cluster-crd.html</span></span><br><span class="line">vi cluster.yaml</span><br><span class="line"><span class="comment"># 创建并查看ceph集群</span></span><br><span class="line">kubectl apply -f cluster.yaml</span><br><span class="line"><span class="comment"># 此时会在无污点的k8s节点上运行csi-pod等pod。然后在相应的rook节点运行rook-ceph-mgr(需要mon选举成功，mgr才会正常运行)、rook-ceph-mon(生成的mon-pod会自动加上Node-Selectors=当前运行节点)、rook-ceph-osd-prepare(进行osd分区等)、rook-ceph-osd对应的pod(也会自动加上Node-Selectors=当前运行节点)。如：rook-ceph-osd-0-5c45f86b4f-nhwzt 则对应 osd0 所在pod(此pod所在节点即为osd0所在节点)</span></span><br><span class="line">kubectl -n rook-ceph get pod -o wide</span><br><span class="line"></span><br><span class="line"><span class="comment">### 配置ceph dashboard</span></span><br><span class="line"><span class="comment"># 创建NodePort服务</span></span><br><span class="line">kubectl apply -f dashboard-external-http.yaml</span><br><span class="line"><span class="comment"># 查看dashboard监听的NodePort端口</span></span><br><span class="line">kubectl -n rook-ceph get service</span><br><span class="line"><span class="comment"># 查看密码(x8sn2X4MPp)，用户名为 admin。如果无法获取密码，可将rook-ceph-mgr删除后重试(或者mgr报错了)</span></span><br><span class="line">kubectl -n rook-ceph logs $(kubectl get pod -n rook-ceph | grep mgr | awk <span class="string">'&#123;print $1&#125;'</span>) | grep password</span><br><span class="line"><span class="comment"># 如访问 http://192.168.6.131:30811/</span></span><br></pre></td></tr></table></figure><ul><li>上文配置文件修改说明</li></ul><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## operator.yaml</span></span><br><span class="line"><span class="comment"># ...</span></span><br><span class="line"><span class="attr">xxx:</span> </span><br><span class="line"><span class="attr">- name:</span> <span class="string">ROOK_CSI_CEPH_IMAGE</span></span><br><span class="line"><span class="attr">  value:</span> <span class="string">"quay.mirrors.ustc.edu.cn/cephcsi/cephcsi:v1.2.1"</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">ROOK_CSI_REGISTRAR_IMAGE</span></span><br><span class="line"><span class="attr">  value:</span> <span class="string">"quay.mirrors.ustc.edu.cn/k8scsi/csi-node-driver-registrar:v1.1.0"</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">ROOK_CSI_PROVISIONER_IMAGE</span></span><br><span class="line"><span class="attr">  value:</span> <span class="string">"quay.mirrors.ustc.edu.cn/k8scsi/csi-provisioner:v1.3.0"</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">ROOK_CSI_SNAPSHOTTER_IMAGE</span></span><br><span class="line"><span class="attr">  value:</span> <span class="string">"quay.mirrors.ustc.edu.cn/k8scsi/csi-snapshotter:v1.2.0"</span></span><br><span class="line"><span class="attr">- name:</span> <span class="string">ROOK_CSI_ATTACHER_IMAGE</span></span><br><span class="line"><span class="attr">  value:</span> <span class="string">"quay.mirrors.ustc.edu.cn/k8scsi/csi-attacher:v1.2.0"</span></span><br><span class="line"><span class="comment"># ...</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## cluster.yaml</span></span><br><span class="line"><span class="comment"># ...</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># 存储rook节点配置信息、日志信息。dataDirHostPath数据存储在k8s节点(宿主机)目录，会自动在rook选择的k8s节点上创建此目录。如果osd目录(directories)没指定或不可用，则默认在此目录创建osd</span></span><br><span class="line">  <span class="comment"># rook对应pod删除后此目录会保留，重新安装rook集群时，此目录必须无文件</span></span><br><span class="line"><span class="attr">  dataDirHostPath:</span> <span class="string">/var/lib/rook</span> <span class="comment"># 默认值即可</span></span><br><span class="line"><span class="attr">  mon:</span></span><br><span class="line">    <span class="comment"># 1-9中的奇数(需要选举)</span></span><br><span class="line"><span class="attr">    count:</span> <span class="number">3</span></span><br><span class="line">    <span class="comment"># 测试环境可设置成true(一个节点可运行多个mon实例)，否则rook-ceph-mgr、rook-ceph-mon、rook-ceph-osd可能无法创建成功(pod不进行调度也不显示错误信息)</span></span><br><span class="line"><span class="attr">    allowMultiplePerNode:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">  network:</span></span><br><span class="line">    <span class="comment"># true表示共享宿主机网络，这样外面可直接连接ceph集群，默认false</span></span><br><span class="line"><span class="attr">    hostNetwork:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># 设置节点亲和性：只能影响rook-ceph-mgr、rook-ceph-mon、rook-ceph-osd；csi相关插件(在operator.yaml中配置的)还是会在除k8s-master的其他各节点上运行</span></span><br><span class="line"><span class="attr">  placement:</span></span><br><span class="line"><span class="attr">    all:</span></span><br><span class="line"><span class="attr">      nodeAffinity:</span></span><br><span class="line"><span class="attr">        requiredDuringSchedulingIgnoredDuringExecution:</span></span><br><span class="line"><span class="attr">          nodeSelectorTerms:</span></span><br><span class="line"><span class="attr">          - matchExpressions:</span></span><br><span class="line"><span class="attr">            - key:</span> <span class="string">storage-node</span></span><br><span class="line"><span class="attr">              operator:</span> <span class="string">In</span></span><br><span class="line"><span class="attr">              values:</span></span><br><span class="line"><span class="bullet">              -</span> <span class="string">enable</span></span><br><span class="line"><span class="attr">  storage:</span></span><br><span class="line">    <span class="comment"># true表示所有k8s节点都可用来部署ceph</span></span><br><span class="line"><span class="attr">    useAllNodes:</span> <span class="literal">false</span></span><br><span class="line">    <span class="comment"># true会把宿主机所有可用的磁盘都用来存储</span></span><br><span class="line"><span class="attr">    useAllDevices:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">    deviceFilter:</span> <span class="string">^sd[b-z]</span> <span class="comment"># 选择k8s节点的sdb、sdc、sdd等开头的设备当做OSD节点。会自动覆盖 `useAllDevices: true`为false。且deviceFilter会被nodes[].devices.name覆盖</span></span><br><span class="line">    <span class="comment"># rook(ceph)数据存放位置，如果无此目录会自动创建</span></span><br><span class="line"><span class="attr">    directories:</span></span><br><span class="line"><span class="attr">    - path:</span> <span class="string">/data/rook</span></span><br><span class="line"><span class="attr">    config:</span></span><br><span class="line">      <span class="comment"># 设备默认是bluestore类型存储，目录默认是filestore存储 (The default and recommended storeType is dynamically set to bluestore for devices and filestore for directories)。如果是bluestore，虽然节点明确定义了devices，还是会在系统目录，如/dev/sda1(dm-0)中创建osd存储</span></span><br><span class="line">      <span class="comment"># storeType: bluestore</span></span><br><span class="line">    <span class="comment"># 选择k8s节点用来存储</span></span><br><span class="line"><span class="attr">    nodes:</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">"node2"</span></span><br><span class="line">      <span class="comment"># 选择k8s节点磁盘设置为OSD节点</span></span><br><span class="line"><span class="attr">      devices:</span></span><br><span class="line">      <span class="comment"># 将/dev/sda2设置为osd。此时sda2进行过分区或挂载也可提供给ceph使用</span></span><br><span class="line">      <span class="comment"># 指定磁盘必须有GPT header，不支持指定分区</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">"sda2"</span></span><br><span class="line"><span class="attr">      directories:</span></span><br><span class="line">      <span class="comment"># rook(ceph)数据存放位置(根据节点自定义，覆盖默认位置)。会自动创建此目录，并创建osd0/osd1...子目录</span></span><br><span class="line"><span class="attr">      - path:</span> <span class="string">"/home/data"</span></span><br><span class="line">    <span class="comment"># 未定义path则使用父属性定义的/data/rook</span></span><br><span class="line"><span class="attr">    - name:</span> <span class="string">"node3"</span></span><br><span class="line">      <span class="comment"># deviceFilter: "^vd." # 选择所有以 vd 开头的设备</span></span><br><span class="line"><span class="attr">      devices:</span></span><br><span class="line">      <span class="comment"># 如果sdb没有进行过分区和挂载，只是物理连接的裸磁盘，rook也会自动进行分区(分区类型为lvm)</span></span><br><span class="line">      <span class="comment"># 尽管定义了devices(和deviceFilter)，rook也会检测到sda的磁盘并创建/var/lib/rook/osd*文件夹，只是无法初始化(且此osd也会注册到ceph)</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">"sdb"</span></span><br><span class="line">      <span class="comment"># 较大存储空间的磁盘上可创建多个osd节点</span></span><br><span class="line">        <span class="comment">#config:</span></span><br><span class="line">        <span class="comment">#  osdsPerDevice: "3"</span></span><br><span class="line"><span class="comment"># ...</span></span><br></pre></td></tr></table></figure><h3 id="简单使用"><a href="#简单使用" class="headerlink" title="简单使用"></a>简单使用</h3><ul><li>块存储案例，参考：<a href="https://rook.io/docs/rook/v1.1/ceph-block.html" target="_blank" rel="noopener">https://rook.io/docs/rook/v1.1/ceph-block.html</a></li><li>实例</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 CephBlockPool 和 StorageClass</span></span><br><span class="line">vi sq-rdb.yaml</span><br><span class="line">kubectl apply -f sq-rdb.yaml</span><br><span class="line">kubectl get sc</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用</span></span><br><span class="line"><span class="built_in">cd</span> /home/smalle/k8s/rook-1.1.2/cluster/examples/kubernetes <span class="comment"># 上文rook源码所在目录</span></span><br><span class="line">kubectl apply -f mysql.yaml <span class="comment"># PVC和Deploy配置参考：https://raw.githubusercontent.com/rook/rook/v1.1.2/cluster/examples/kubernetes/mysql.yaml</span></span><br><span class="line">kubectl get pvc</span><br><span class="line"><span class="comment"># 稍等片刻，临时主机暴露端口。使用 192.168.6.131:13306 root/changeme 访问 mysql</span></span><br><span class="line">kubectl port-forward --address 0.0.0.0 $(kubectl get pods --namespace default -l <span class="string">"app=wordpress,tier=mysql"</span> -o jsonpath=<span class="string">"&#123;.items[0].metadata.name&#125;"</span>) 13306:3306</span><br><span class="line"></span><br><span class="line"><span class="comment">## **解析RBD存储**：当PVC申请PV，PV挂载到POD上后，可在rook节点(OSD所在k8s节点)中看到rbd挂载信息</span></span><br><span class="line"><span class="comment"># 在rook节点上运行，可以看到 rbd0(/dev/rbd0) 磁盘被挂载到了 /var/lib/kubelet/pods/bd1de507...目录上</span></span><br><span class="line">lsblk</span><br><span class="line"><span class="comment"># 进入此目录，可以看到完整的文件信息。如mysql完整的数据文件</span></span><br><span class="line"><span class="built_in">cd</span> /var/lib/kubelet/pods/bd1de507-39ac-47fa-b1e2-a19a1107ef01/volumes/kubernetes.io~csi/pvc-6f9dce55-3203-4a4d-8ea1-0d75e6563d77/mount</span><br><span class="line"><span class="comment"># 也可在对应节点运行查看挂载 (**还可看到pvc对应磁盘使用情况**)</span></span><br><span class="line">df -h | grep csi/pvc</span><br></pre></td></tr></table></figure><ul><li>sq-rdb.yaml</li></ul><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## replicapool-test.yaml</span></span><br><span class="line"><span class="comment"># CephBlockPool 设置参考 https://rook.io/docs/rook/v1.1/ceph-pool-crd.html</span></span><br><span class="line"><span class="comment"># 存储集群运行中时，也可修改下列参数</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">ceph.rook.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">CephBlockPool</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">replicapool-test</span></span><br><span class="line">  <span class="comment"># CephBlockPool定义在rook-ceph命名空间接口；其他各个命名空间的StorageClass可通过parameters进行制定CephBlockPool所在的命名空间来进行连接</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line">  <span class="comment"># 取值：host、osd</span></span><br><span class="line">  <span class="comment"># host：所有块都将放置在唯一的主机上；osd：所有块都将放置在唯一的OSD上(一个主机可能存在多个osd)</span></span><br><span class="line"><span class="attr">  failureDomain:</span> <span class="string">host</span></span><br><span class="line">  <span class="comment"># 复制池设置(简单的文件数据复制，和erasureCoded不能同时设置)</span></span><br><span class="line"><span class="attr">  replicated:</span></span><br><span class="line">    <span class="comment"># 要在复制池中制作数据的所需副本数(副本数为3时，如果其中2个几点宕机，还是可以正常提供服务)</span></span><br><span class="line">    <span class="comment"># 如果池中没有足够的主机或OSD来放置唯一位置，也可以创建此k8s池(ceph集群中不会进行创建对应pool)，但是该池的PUT会挂起，PVC也一直处于Pending状态</span></span><br><span class="line"><span class="attr">    size:</span> <span class="number">3</span> <span class="comment"># 测试环境可设置成1</span></span><br><span class="line">  <span class="comment"># 擦除编码池设置(将数据分成数据块数和编码块，总存储一般高于原始数据的1.5倍左右。如果损失其中任意一块，仍然能够重建原始对象)。仅仅在Flex驱动中可用</span></span><br><span class="line">  <span class="comment"># erasureCoded:</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment">## rook-ceph-block.yaml</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">storage.k8s.io/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StorageClass</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">rook-ceph-block</span> <span class="comment"># 在PVC中会使用到</span></span><br><span class="line"><span class="comment"># CSI驱动。如果rook-ceph集群所在k8s命名空间为`xxx`，则此处为`xxx.rbd.csi.ceph.com`</span></span><br><span class="line"><span class="attr">provisioner:</span> <span class="string">rook-ceph.rbd.csi.ceph.com</span></span><br><span class="line"><span class="comment"># Flex驱动(parameters也要做相应修改，K8 1.13已经不推荐)</span></span><br><span class="line"><span class="comment"># provisioner: ceph.rook.io/block</span></span><br><span class="line"><span class="attr">parameters:</span></span><br><span class="line"><span class="attr">  clusterID:</span> <span class="string">rook-ceph</span></span><br><span class="line">  <span class="comment"># 上文定义的pool名称</span></span><br><span class="line"><span class="attr">  pool:</span> <span class="string">replicapool-test</span></span><br><span class="line"><span class="attr">  imageFormat:</span> <span class="string">"2"</span></span><br><span class="line"><span class="attr">  imageFeatures:</span> <span class="string">layering</span></span><br><span class="line">  <span class="comment"># 安装集群时，operator自动产生的相关秘钥，可在rook-ceph对应命名空间中查看</span></span><br><span class="line">  <span class="string">csi.storage.k8s.io/provisioner-secret-name:</span> <span class="string">rook-ceph-csi</span></span><br><span class="line">  <span class="string">csi.storage.k8s.io/provisioner-secret-namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line">  <span class="string">csi.storage.k8s.io/node-stage-secret-name:</span> <span class="string">rook-ceph-csi</span></span><br><span class="line">  <span class="string">csi.storage.k8s.io/node-stage-secret-namespace:</span> <span class="string">rook-ceph</span></span><br><span class="line">  <span class="comment"># 指定申请的卷的文件系统类型，默认是`ext4`</span></span><br><span class="line">  <span class="string">csi.storage.k8s.io/fstype:</span> <span class="string">xfs</span></span><br><span class="line"><span class="comment"># 删除PVC时删除RBD卷。Delete(只会删除PV和PVC，不会删除rbd)、Retain(生成环境可使用)、Recycle</span></span><br><span class="line"><span class="attr">reclaimPolicy:</span> <span class="string">Delete</span></span><br></pre></td></tr></table></figure><h3 id="使用扩展"><a href="#使用扩展" class="headerlink" title="使用扩展"></a>使用扩展</h3><h3 id="增加-减少OSD节点"><a href="#增加-减少OSD节点" class="headerlink" title="增加/减少OSD节点"></a>增加/减少OSD节点</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 增加节点。不会影响其他运行中的ceph节点</span></span><br><span class="line"><span class="comment"># 增加节点亲和性相关的标签(需要先加标签后应用cluster配置)</span></span><br><span class="line">kubectl label nodes node4 storage-node=<span class="built_in">enable</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改集群配置：设置 spec.storage.nodes</span></span><br><span class="line"><span class="comment"># kubectl edit cephcluster rook-ceph -n rook-ceph # 或者直接修改资源</span></span><br><span class="line"><span class="built_in">cd</span> /home/smalle/k8s/rook-1.1.2/cluster/examples/kubernetes/ceph/</span><br><span class="line">vi cluster.yaml</span><br><span class="line">kubectl apply -f cluster.yaml</span><br><span class="line"></span><br><span class="line"><span class="comment"># 实时查看pod调度情况(需要等1分钟左右)，会多一个 rook-ceph-osd-prepare-node4、rook-ceph-osd(其中rook-ceph-osd运行正常后prepare-pod会自动进入完成状态)</span></span><br><span class="line">kubectl -n rook-ceph get pod -o wide -w</span><br><span class="line"><span class="comment"># 如果osd-pod一直不产生，可删除对应节点的prepare-pod重新创建。如果prepare-pod一直处于CrashLoopBackOff之后会被k8s清除，大概要等15min才会重新创建</span></span><br><span class="line"><span class="comment"># kubectl -n rook-ceph delete pods rook-ceph-detect-version-ps5g9</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### 删除节点</span></span><br><span class="line"><span class="comment"># 去掉节点标签</span></span><br><span class="line">kubectl label nodes node4 storage-node-</span><br><span class="line"><span class="comment"># 删除集群配置中的 spec.storage.nodes</span></span><br><span class="line"><span class="comment"># 如果pod一直无法成功删除，可重启此节点机器，有时删除确实很慢(15min)。**如果只有一个osd节点或者集群空间不足，则该节点无法被自动删除**</span></span><br><span class="line">kubectl edit cephcluster rook-ceph -n rook-ceph</span><br><span class="line">kubectl -n rook-ceph get pod -o wide -w <span class="comment"># 对应节点的osd-pod会被移除</span></span><br><span class="line"><span class="comment"># 等pod移除成功后，再删除宿主机的/var/lib/rook/osd*文件夹(如果osd数据目录为其他自定义目录可相应删除)，方便下次将此节点再加入集群</span></span><br><span class="line"><span class="comment"># 注意：/var/lib/rook目录还可能有mon等pod的配置，不能删除</span></span><br><span class="line">rm -rf /var/lib/rook/osd*</span><br><span class="line"><span class="comment"># (可选)还原磁盘供下次安装osd使用</span></span><br><span class="line"><span class="comment"># yum install -y gdisk</span></span><br><span class="line">sgdisk --zap-all --clear --mbrtogpt /dev/sdb</span><br><span class="line">/usr/sbin/wipefs --all /dev/sdb</span><br><span class="line">ls /dev/mapper/ceph-* | xargs -I% -- dmsetup remove %</span><br><span class="line">rm -rf /dev/mapper/ceph-*</span><br><span class="line">rm -rf /dev/ceph-*</span><br></pre></td></tr></table></figure><h3 id="删除整个集群"><a href="#删除整个集群" class="headerlink" title="删除整个集群"></a>删除整个集群</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 备份数据后再操作</span></span><br><span class="line"><span class="built_in">cd</span> /home/smalle/k8s/rook-1.1.2/cluster/examples/kubernetes/ceph/</span><br><span class="line"><span class="comment">## 删除测试案例相关资源(可选)</span></span><br><span class="line"><span class="comment"># kubectl delete -n rook-ceph cephblockpool replicapool-test</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 删除rook-ceph集群并检查</span></span><br><span class="line">kubectl -n rook-ceph delete cephcluster rook-ceph <span class="comment"># 如果删除失败可以先执行下述命令</span></span><br><span class="line"><span class="comment"># (可选)如果无法删除可运行此命令</span></span><br><span class="line"><span class="comment"># kubectl -n rook-ceph patch crd cephclusters.ceph.rook.io --type merge -p '&#123;"metadata":&#123;"finalizers": [null]&#125;&#125;'</span></span><br><span class="line">kubectl -n rook-ceph get cephcluster</span><br><span class="line"><span class="comment">## 删除operator及相关资源</span></span><br><span class="line">kubectl delete -f operator.yaml</span><br><span class="line">kubectl delete -f common.yaml</span><br><span class="line"><span class="comment"># 所有rook节点运行，删除rook集群数据</span></span><br><span class="line">rm -rf /var/lib/rook</span><br><span class="line"></span><br><span class="line"><span class="comment">## 在rook集群使用到的k8s节点上，**备份数据后删除**</span></span><br><span class="line"><span class="comment"># 删除所有分区，需要对所有用到的磁盘进行操作。sgdisk是Linux下操作GPT分区的工具，就像fdisk是操作MBR分区的工具</span></span><br><span class="line"><span class="comment"># yum install -y gdisk # 安装sgdisk工具。参考[shell](/_posts/linux/shell.md#linux命令)</span></span><br><span class="line">sgdisk --zap-all /dev/sdb</span><br><span class="line">/usr/sbin/wipefs --all /dev/sdb</span><br><span class="line"><span class="comment"># 在每个节点上删除映射</span></span><br><span class="line">ls /dev/mapper/ceph-* | xargs -I% -- dmsetup remove %</span><br><span class="line">rm -rf /dev/mapper/ceph-*</span><br><span class="line">rm -rf /dev/ceph-*</span><br><span class="line"><span class="comment"># 删除osd节点的数据目录</span></span><br><span class="line">rm -rf /data/rook</span><br></pre></td></tr></table></figure><h3 id="Ceph工具箱"><a href="#Ceph工具箱" class="headerlink" title="Ceph工具箱"></a>Ceph工具箱</h3><ul><li>安装相应pod</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /root/k8s/rook-1.1.2/cluster/examples/kubernetes/ceph <span class="comment"># 上文安装目录</span></span><br><span class="line"><span class="comment"># 可修改 `spec.template.spec.nodeSelector: kubernetes.io/hostname: node3` 让此pod运行在某个节点上(此工具部署在哪个节点就只能操作哪个节点)</span></span><br><span class="line">kubectl apply -f toolbox.yaml</span><br><span class="line">kubectl -n rook-ceph get pod -l <span class="string">"app=rook-ceph-tools"</span> -o wide</span><br><span class="line"><span class="comment"># 连接此pod。如果pod运行在node3，则连接后命令行显示成node3(类似ssh连接node3)，然后运行ceph相关命令(不能直接在node3上运行)</span></span><br><span class="line">kubectl -n rook-ceph <span class="built_in">exec</span> -it $(kubectl -n rook-ceph get pod -l <span class="string">"app=rook-ceph-tools"</span> -o jsonpath=<span class="string">'&#123;.items[0].metadata.name&#125;'</span>) bash</span><br><span class="line"><span class="comment"># 连接pod后运行ceph命令</span></span><br><span class="line">ceph status</span><br><span class="line"><span class="comment"># 使用完工具箱后，可以删除部署</span></span><br><span class="line">kubectl -n rook-ceph delete deployment rook-ceph-tools</span><br></pre></td></tr></table></figure><h3 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h3><h4 id="测试案例"><a href="#测试案例" class="headerlink" title="测试案例"></a>测试案例</h4><ul><li>Ceph OSD 存储空间不足，会导致Pod调度失败，一直处于Pending状态</li><li>PVC申请100M<ul><li>上传一个大于100M的文件，在差不多100M处卡死，然后提示出错(文件没有上传上去)。重新上传一个小文件是可正常上传的</li><li>使用ceph工具 <code>rbd du replicapool-test/csi-vol-0f73ed14-df67-11e9-8202-1294917b9bfd</code> 显示的PROVISIONED和USED都是100M(实际只用了几M)</li></ul></li><li>rdb数据位置和可用性<ul><li><code>lsblk</code> 可查看pvc申请创建的rdb存储块，此处/dev/rbd0类似一个虚拟磁盘</li><li>rdb存储块创建后，即使删除整个ceph集群，rdb数据也会保留；删除osd0等目录，rdb存储块上的数据也不会丢失</li><li><code>rook-ceph-osd-osd-0-xxx</code> 对应的所有pod停止运行也不会影响之前创建的rdb磁盘的使用；但是如果<code>rook-ceph-mon-pod</code>无法正常运行或选举则rdb磁盘无法读写</li></ul></li></ul><h4 id="备注"><a href="#备注" class="headerlink" title="备注"></a>备注</h4><ul><li>原理说明<ul><li><code>rook-ceph-operator-pod</code> 是整个集群的管理者</li><li><code>rook-discover-pod</code>是运行在每个k8s节点上的守护进程，用来探测改节点是否有可用磁盘(如刚进行连接的空磁盘)</li><li>如果发现则将参数传递给对应节点的osd创建器，如<code>rook-ceph-osd-prepare-node3-pod</code>。会接受到参数如 <i>rookcmd: flag values: –cluster-id=85e086d5-6017-4c52-85d7-e266a82ae382, –data-device-filter=, –data-devices=sdb:1:::, –data-directories=/data/rook, –encrypted-device=false, –force-format=false, –help=false, –location=, –log-flush-frequency=5s, –log-level=INFO, –metadata-device=, –node-name=node3, –operator-image=, –osd-database-size=0, –osd-journal-size=5120, –osd-store=, –osd-wal-size=576, –osds-per-device=1, –pvc-backed-osd=false, –service-account=, –topology-aware=false</i></li><li><code>rook-ceph-osd-prepare-node3-pod</code>主要负责创建osd，包括在/data/rook创建类似osd0的子目录。此pod由job控制器<code>rook-ceph-osd-prepare-node3</code>进行控制，可describe查看此job的任务描述</li></ul></li></ul><h3 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h3><ul><li>排错技巧</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看Rook pod状态</span></span><br><span class="line">kubectl get pod -n rook-ceph -o wide</span><br><span class="line"><span class="comment"># 查看Rook pods日志</span></span><br><span class="line">kubectl logs -n rook-ceph -l app=rook-ceph-operator <span class="comment"># **查看operator日志**：operator会负责连接mon服务，只有mon选举成功，才会启动osd服务</span></span><br><span class="line">kubectl logs -n rook-ceph -l mon=a</span><br><span class="line"><span class="comment"># 登录特定k8s节点以查找PVC挂载失败的原因</span></span><br><span class="line">journalctl -u kubelet -f -n 100 <span class="comment"># 查看kubelet日志</span></span><br><span class="line"><span class="comment"># 有多个容器的pods</span></span><br><span class="line">kubectl -n rook-ceph logs &lt;pod-name&gt; --all-containers <span class="comment"># 对于所有容器</span></span><br><span class="line">kubectl -n rook-ceph logs &lt;pod-name&gt; -c &lt;container-name&gt; <span class="comment"># 对于单个容器</span></span><br><span class="line">kubectl -n rook-ceph logs --previous &lt;pod-name&gt; <span class="comment"># 不再运行的Pod的日志</span></span><br></pre></td></tr></table></figure><ul><li>常见问题</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">### 问题日志 </span></span><br><span class="line"><span class="comment">## 1.存储消费者(Pod)报错："Unable to mount volumes for pod "sq-rook-ceph-ftp_default(829ca564-9f3b-4017-8eb2-feac02c0fbe1)": timeout expired waiting for volumes to attach or mount for pod "default"/"sq-rook-ceph-ftp". list of unmounted volumes=[ftp-data]. list of unattached volumes=[ftp-data default-token-bmlnx]"</span></span><br><span class="line"><span class="comment"># 检查rook-ceph是否正常运行</span></span><br><span class="line"><span class="comment"># `kubectl get pv`、`kubectl get pvc`确保都处于Bound状态，否则查看 rook-ceph-operator 日志</span></span><br><span class="line">kubectl -n rook-ceph logs `kubectl -n rook-ceph -l app=rook-ceph-operator get pods -o jsonpath=<span class="string">'&#123;.items[*].metadata.name&#125;'</span>`</span><br><span class="line"></span><br><span class="line"><span class="comment">## 2.operator-pod报错："ceph mon_status exec: timed out"。且此时只有operator-pod运行，osd-pod未运行，且只有一个mon-a-pod处于运行状态，dashboard也无法访问</span></span><br><span class="line"><span class="comment"># 参考 https://rook.io/docs/rook/v1.1/ceph-common-issues.html#Monitors are the only pods running</span></span><br><span class="line"><span class="comment"># 可能原因：operator-pod与mon-pod网络不通；mon-pod无法启动；一个或多个mon-pod处于运行状态，但无法选举成功</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 3.mon-abd-pod运行中，osd-prepare-pod-node3运行中，osd-pod一直未运行，dashboard可以访问。查看osd-prepare-pod日志显示cephosd: skipping device sda that is in use (not by rook). fs: , ownPartitions: false；cephosd: no more devices to configure。且此之前node3处于rook集群中，被rook进行了分区和挂载</span></span><br><span class="line"><span class="comment"># cluster.yaml中的spec.storage.nodes使用无分区的裸磁盘</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 4.prepare-pod日志显示："ceph-volume lvm batch: error: GPT headers found, they must be removed on: /dev/sdb"。且osd-pod也不会创建，prepare-pod一直处于CrashLoopBackOff状态，之后被k8s清除，大概要等15min才会重新创建</span></span><br><span class="line"><span class="comment"># 需要重新清空磁盘分区，参考上文"删除整个集群"</span></span><br><span class="line">sgdisk --zap-all /dev/sdb <span class="comment"># 格式化</span></span><br><span class="line">/usr/sbin/wipefs --all /dev/sdb <span class="comment"># 擦除磁盘</span></span><br><span class="line"><span class="comment"># (解决)测试时操作上述命令情况也无法成功，然后通过ceph-toolbox(需要运行在此问题节点上)手动运行命令分区后，osd-pod成功创建。参考：https://forum.proxmox.com/threads/recommended-way-of-creating-multiple-osds-per-nvme-disk.52252/</span></span><br><span class="line"><span class="comment"># 上述错误实际是运行`stdbuf -oL ceph-volume lvm batch --prepare --bluestore --yes --osds-per-device 1 /dev/sdb --report`此命令导致的</span></span><br><span class="line">ceph-volume lvm zap --destroy /dev/sdb <span class="comment"># ceph-volume格式化命令</span></span><br><span class="line"><span class="comment"># 主要是通过ceph-volume执行zap，此命令也可交由prepare-pod自动完成</span></span><br><span class="line">ceph-volume lvm batch --osds-per-device 1 /dev/sdb <span class="comment"># 参考下文ceph-volume部分，batch表示基于已有的OSDs进行修改</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 5.集群在初始化后，operator会自动给mon-pod添加`Node-Selectors:  kubernetes.io/hostname=xxx`</span></span><br><span class="line"><span class="comment"># mon-pod 是有状态服务，rook将其状态写入dataDirHostPath。自动加上Node-Selectors以备重新创建mon也在改机器上，从而可以获取之前mon的配置数据</span></span><br><span class="line"><span class="comment"># 设计参考：https://github.com/rook/rook/blob/master/design/mon-health.md</span></span><br><span class="line"><span class="comment"># osd-pod也是如此会自动添加Node-Selectors</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 6.osd-pod提示"PostStartHookError: command 'chown --recursive ceph:ceph /var/log/ceph /home/data/osd1' exited with 126"</span></span><br><span class="line"><span class="comment"># 测试是改osd1无法成功移除，可删除对应osd-deploy</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## 7.operator-pod一直提示"op-k8sutil: batch job rook-ceph-detect-version still exists"</span></span><br><span class="line"><span class="comment"># 可强制删除rook-ceph-detect-version重新创建pod</span></span><br></pre></td></tr></table></figure><hr><p>参考文章</p></div><div></div><div></div><div><ul class="post-copyright"><li class="post-copyright-author"> <strong>本文作者：</strong> smalle</li><li class="post-copyright-link"> <strong>本文链接：</strong> <a href="http://blog.aezo.cn/2019/09/23/devops/rook/" title="Rook | K8s存储协调器">http://blog.aezo.cn/2019/09/23/devops/rook/</a></li><li class="post-copyright-license"> <strong>版权声明：</strong> 本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-tags"> <a href="/tags/k8s/" rel="tag"># k8s</a> <a href="/tags/cncf/" rel="tag"># cncf</a> <a href="/tags/storage/" rel="tag"># storage</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2019/09/19/devops/prometheus/" rel="next" title="Prometheus"><i class="fa fa-chevron-left"></i> Prometheus</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"> <a href="/2019/09/26/extend/soft-test/" rel="prev" title="软件测试">软件测试<i class="fa fa-chevron-right"></i></a></div></div></footer></article><div class="post-spread"><div> <a target="_blank" href="https://github.com/oldinaction/ChatGPT-MP"><img class="nofancybox" style="width:300px;margin:0 auto" src="https://cdn7.aezo.cn/one/chat/chat-gpt-open-banner.jpg" alt="ChatGPT开源小程序" title="ChatGPT开源小程序"></a></div></div></div></div><div class="comments" id="comments"></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap"> 文章目录</li><li class="sidebar-nav-overview" data-target="site-overview"> 站点概览</li></ul><section class="site-overview sidebar-panel"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"> <img class="site-author-image" itemprop="image" src="https://avatars0.githubusercontent.com/u/15698218?v=3&u=ce740bf0b67ff0d74990ba6fc644d6e92f572dcb&s=400" alt="smalle"><p class="site-author-name" itemprop="name">smalle</p><p class="site-description motion-element" itemprop="description"></p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">163</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/index.html"><span class="site-state-item-count">13</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/index.html"><span class="site-state-item-count">146</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div><div class="links-of-author motion-element"></div><div> 欢迎关注公众号：阿壹族 <img class="nofancybox" style="width:120px;margin:0 auto" src="https://cdn7.aezo.cn/common/qrcode/ayz_qrcode.jpg" alt="欢迎关注公众号：阿壹族" title="欢迎关注公众号：阿壹族"></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#简介"><span class="nav-number">1.</span> <span class="nav-text">简介</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Rook-Ceph"><span class="nav-number">2.</span> <span class="nav-text">Rook-Ceph</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#安装-Rook-Ceph"><span class="nav-number">2.1.</span> <span class="nav-text">安装 Rook-Ceph</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简单使用"><span class="nav-number">2.2.</span> <span class="nav-text">简单使用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#使用扩展"><span class="nav-number">2.3.</span> <span class="nav-text">使用扩展</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#增加-减少OSD节点"><span class="nav-number">2.4.</span> <span class="nav-text">增加/减少OSD节点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#删除整个集群"><span class="nav-number">2.5.</span> <span class="nav-text">删除整个集群</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Ceph工具箱"><span class="nav-number">2.6.</span> <span class="nav-text">Ceph工具箱</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#说明"><span class="nav-number">2.7.</span> <span class="nav-text">说明</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#测试案例"><span class="nav-number">2.7.1.</span> <span class="nav-text">测试案例</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#备注"><span class="nav-number">2.7.2.</span> <span class="nav-text">备注</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#常见问题"><span class="nav-number">2.8.</span> <span class="nav-text">常见问题</span></a></li></ol></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright"> &copy; 2016 - <span itemprop="copyrightYear">2023</span><span class="with-love"><i class="fa fa-heart"></i></span> <span class="author" itemprop="copyrightHolder">smalle</span>&nbsp;&nbsp;&nbsp;&nbsp;<div class="powered-by"> 由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div><div class="powered-by"> 主题 - <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a></div><div class="theme-info"> <a class="theme-link" target="_blank" href="https://tongji.baidu.com/main/overview/10000542408/overview/index?siteId=18991897">站长统计</a></div></div><div class="ad"> <span style="font-weight:700">AD&nbsp;&nbsp;&nbsp;&nbsp;</span><div class="theme-info"> <a target="_blank" href="https://promotion.aliyun.com/ntms/yunparter/invite.html?userCode=oby5nolb">阿里云大礼包</a></div></div><div class="aezocn"> <span style="font-weight:700">&copy;AEZO.CN&nbsp;&nbsp;&nbsp;&nbsp;</span><div class="powered-by"> <a target="_blank" href="https://shengqitech.aezo.cn/">圣骑科技</a></div><div class="powered-by"> <a target="_blank" href="https://cdn7.aezo.cn/common/qrcode/one_qrcode.jpg">【One能抽屉】小程序</a></div><div class="theme-info"> <a target="_blank" href="http://shop.aezo.cn/">杂货铺(省钱小助手)</a></div></div><script type="text/javascript">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?085f9cd91ef2ad985f791c677472f0d1";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script><script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script><script>!function(){var t=document.createElement("script"),e=window.location.protocol.split(":")[0];t.src="https"===e?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js";var s=document.getElementsByTagName("script")[0];s.parentNode.insertBefore(t,s)}()</script><script type="text/javascript" src="/js/src/js.cookie.js?v=5.1.1"></script><script type="text/javascript" src="/js/src/scroll-cookie.js?v=5.1.1"></script></body></html>